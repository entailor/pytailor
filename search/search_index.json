{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Pytailor documentation Pytailor is a python client for the Tailor automation and collaboration platform. See Tailor.wf for more information.","title":"Home"},{"location":"#welcome-to-the-pytailor-documentation","text":"Pytailor is a python client for the Tailor automation and collaboration platform. See Tailor.wf for more information.","title":"Welcome to the Pytailor documentation"},{"location":"api/parameterization/","text":"Parameterization Classes Inputs class pytailor. Inputs ( ) Helper object for inputs parameterization. Basic usage from pytailor import PythonTask , DAG , Inputs , Workflow , Project inputs = Inputs () with DAG () as dag : PythonTask ( function = 'builtins.print' , args = inputs . hello , ) prj = Project . from_name ( \"Test\" ) wf = Workflow ( dag = dag , project = prj , inputs = { \"hello\" : [ \"Hello, world!\" ]} ) wf . run () Outputs class pytailor. Outputs ( ) Helper object for outputs parameterization. Basic usage from pytailor import PythonTask , DAG , Outputs , Workflow , Project outputs = Outputs () with DAG () as dag : t1 = PythonTask ( function = 'os.getcwd' , output_to = outputs . curdir ) PythonTask ( function = 'builtins.print' , args = [ outputs . curdir ], ) prj = Project . from_name ( \"Test\" ) wf = Workflow ( dag = dag , project = prj , ) wf . run () print ( wf . outputs ) Files class pytailor. Files ( ) Helper object for files parameterization. Basic usage from pytailor import PythonTask , DAG , Files , Workflow , Project , FileSet files = Files () with DAG () as dag : PythonTask ( function = 'builtins.print' , args = [ \"This tasks download the file:\" , files . inpfile [ 0 ]], download = files . inpfile ) prj = Project . from_name ( \"Test\" ) fileset = FileSet ( project = prj ) fileset . upload ( inpfile = [ \"my_file.txt\" ]) wf = Workflow ( dag = dag , project = prj , fileset = fileset ) wf . run ()","title":"Parameterization classes"},{"location":"api/parameterization/#parameterization-classes","text":"","title":"Parameterization Classes"},{"location":"api/parameterization/#inputs","text":"class pytailor. Inputs ( ) Helper object for inputs parameterization. Basic usage from pytailor import PythonTask , DAG , Inputs , Workflow , Project inputs = Inputs () with DAG () as dag : PythonTask ( function = 'builtins.print' , args = inputs . hello , ) prj = Project . from_name ( \"Test\" ) wf = Workflow ( dag = dag , project = prj , inputs = { \"hello\" : [ \"Hello, world!\" ]} ) wf . run ()","title":"Inputs"},{"location":"api/parameterization/#outputs","text":"class pytailor. Outputs ( ) Helper object for outputs parameterization. Basic usage from pytailor import PythonTask , DAG , Outputs , Workflow , Project outputs = Outputs () with DAG () as dag : t1 = PythonTask ( function = 'os.getcwd' , output_to = outputs . curdir ) PythonTask ( function = 'builtins.print' , args = [ outputs . curdir ], ) prj = Project . from_name ( \"Test\" ) wf = Workflow ( dag = dag , project = prj , ) wf . run () print ( wf . outputs )","title":"Outputs"},{"location":"api/parameterization/#files","text":"class pytailor. Files ( ) Helper object for files parameterization. Basic usage from pytailor import PythonTask , DAG , Files , Workflow , Project , FileSet files = Files () with DAG () as dag : PythonTask ( function = 'builtins.print' , args = [ \"This tasks download the file:\" , files . inpfile [ 0 ]], download = files . inpfile ) prj = Project . from_name ( \"Test\" ) fileset = FileSet ( project = prj ) fileset . upload ( inpfile = [ \"my_file.txt\" ]) wf = Workflow ( dag = dag , project = prj , fileset = fileset ) wf . run ()","title":"Files"},{"location":"api/schema/","text":"Schema Definition Classes InputsSchema class pytailor. InputsSchema ( inputs ) Generator for inputsschema to define workflow definition Basic usage Following example define a jsonschema, that sets \"print\" as a required property for inputs and that the value must be a string example_inputs = { 'print' : 'Hello, world!' } inputsschema = InputsSchema ( inputs = example_inputs ) Add 'Hello, world' as a default for property 'print' example_inputs = { 'print' : 'Hello, world!' } inputsschema . add_defaults ( example_inputs ) # Set 'Hello, world' and 'Hello, tailor!' as only allowed alternatives for property 'print': enum_inputs = { 'print' : [ 'Hello, world!' , 'Hello, tailor!' ]} inputsschema . add_enums ( enum_inputs ) Parameters inputs (dict) Specify an example input schema that is valid for your workflow definition. add_defaults ( self , default_inputs ) Parameters default_inputs (dict) S Specify an example input schema that is valid for your workflow definition with defaults. add_enums ( self , enum_inputs ) Parameters enum_inputs (dict) S Specify altenatives for your inputsschema with a input schema where the property's values in a list represents the alternatives to_dict ( self ) Serialize input schema to_json ( self , filename , indent=4 ) a json file FilesSchema class pytailor. FilesSchema ( tags=None , exts=None , multiples=None , requireds=None , titles=None , descriptions=None ) Generator for filesschema to define workflow definition Basic usage files_ex1 = { \"tag\" : \"my_tag\" , \"ext\" : [ \"txt\" ], } filesschema = FilesSchema () filesschema . add_file ( tag = \"my_tag\" , ext = [ \"txt\" ]) files_ex2 = { \"tag\" : \"my__new_tag\" , \"ext\" : [ \"txt\" ], \"title\" : \"Coordinates\" , \"multiple\" : True , \"description\" : \"A file with coordinate values of nodes\" , \"required\" : True , } filesschema = FilesSchema () filesschema . add_file ( ** files_ex2 ) Parameters inputs (dict) Specify an example input schema that is valid for your workflow definition. add_file ( self , tag , ext=None , multiple=False , required=True , title=None , description='' ) Parameters tag (str) Specify tag for file. tag (str) Specify allowed extension for file mutiple (bool) Specify whether multiples files are allowed required (bool) Specify whether file(s) are required title (str) Specify the title to be shown in GUI description (str) Specify the description to be shown in GUI to_dict ( self ) Serialize files schema to_json ( self , filename , indent=4 ) Description class pytailor. Description ( name=None , description_string=None ) Workflow definition description generator to define workflow definition Basic usage wf_def_description = \"This example explains branchtasks\" wf_def_name = \"branch task example\" from pytailor import PythonTask , BranchTask , DAG with DAG ( name = \"duplicate dag example\" ) as dag : with BranchTask ( name = \"branch\" , branch_data = [ \"<% $.files.testfiles %>\" ], branch_files = [ \"testfiles\" ], ): with DAG ( name = \"sub-dag\" ) as sub_dag : t1 = PythonTask ( function = \"glob.glob\" , name = \"task 2\" , args = [ \"* / .txt\" ], kwargs = { \"recursive\" : True }, download = \"testfiles\" , output_to = \"glob_res\" , ) PythonTask ( function = \"builtins.print\" , name = \"task 3\" , args = [ \"<% $.files.testfiles %>\" , \"<% $.outputs.glob_res %>\" ], parents = t1 , ) description = Description . from_dag ( dag , wf_def_name = wf_def_name , wf_def_description = wf_def_description ) Parameters name (dict) Specify a name for the workflow definition description_string (str) Specify a description string in markdown format from_dag ( dag , wf_def_name='' , wf_def_description='' ) Generates a workflow definition description from a pytailor DAG class Parameters dag (DAG) Specify your DAG for workflow definition wf_def_name (str) Specify a name for workflow definition wf_def_description (str) Specify an overall description, what are the main objectives of your workflow definition? What are the main steps in the DAG? to_string ( self ) to_markdown ( self , filename='Readme.MD' )","title":"Schema definition classes"},{"location":"api/schema/#schema-definition-classes","text":"","title":"Schema Definition Classes"},{"location":"api/schema/#inputsschema","text":"class pytailor. InputsSchema ( inputs ) Generator for inputsschema to define workflow definition Basic usage Following example define a jsonschema, that sets \"print\" as a required property for inputs and that the value must be a string example_inputs = { 'print' : 'Hello, world!' } inputsschema = InputsSchema ( inputs = example_inputs ) Add 'Hello, world' as a default for property 'print' example_inputs = { 'print' : 'Hello, world!' } inputsschema . add_defaults ( example_inputs ) # Set 'Hello, world' and 'Hello, tailor!' as only allowed alternatives for property 'print': enum_inputs = { 'print' : [ 'Hello, world!' , 'Hello, tailor!' ]} inputsschema . add_enums ( enum_inputs ) Parameters inputs (dict) Specify an example input schema that is valid for your workflow definition. add_defaults ( self , default_inputs ) Parameters default_inputs (dict) S Specify an example input schema that is valid for your workflow definition with defaults. add_enums ( self , enum_inputs ) Parameters enum_inputs (dict) S Specify altenatives for your inputsschema with a input schema where the property's values in a list represents the alternatives to_dict ( self ) Serialize input schema to_json ( self , filename , indent=4 ) a json file","title":"InputsSchema"},{"location":"api/schema/#filesschema","text":"class pytailor. FilesSchema ( tags=None , exts=None , multiples=None , requireds=None , titles=None , descriptions=None ) Generator for filesschema to define workflow definition Basic usage files_ex1 = { \"tag\" : \"my_tag\" , \"ext\" : [ \"txt\" ], } filesschema = FilesSchema () filesschema . add_file ( tag = \"my_tag\" , ext = [ \"txt\" ]) files_ex2 = { \"tag\" : \"my__new_tag\" , \"ext\" : [ \"txt\" ], \"title\" : \"Coordinates\" , \"multiple\" : True , \"description\" : \"A file with coordinate values of nodes\" , \"required\" : True , } filesschema = FilesSchema () filesschema . add_file ( ** files_ex2 ) Parameters inputs (dict) Specify an example input schema that is valid for your workflow definition. add_file ( self , tag , ext=None , multiple=False , required=True , title=None , description='' ) Parameters tag (str) Specify tag for file. tag (str) Specify allowed extension for file mutiple (bool) Specify whether multiples files are allowed required (bool) Specify whether file(s) are required title (str) Specify the title to be shown in GUI description (str) Specify the description to be shown in GUI to_dict ( self ) Serialize files schema to_json ( self , filename , indent=4 )","title":"FilesSchema"},{"location":"api/schema/#description","text":"class pytailor. Description ( name=None , description_string=None ) Workflow definition description generator to define workflow definition Basic usage wf_def_description = \"This example explains branchtasks\" wf_def_name = \"branch task example\" from pytailor import PythonTask , BranchTask , DAG with DAG ( name = \"duplicate dag example\" ) as dag : with BranchTask ( name = \"branch\" , branch_data = [ \"<% $.files.testfiles %>\" ], branch_files = [ \"testfiles\" ], ): with DAG ( name = \"sub-dag\" ) as sub_dag : t1 = PythonTask ( function = \"glob.glob\" , name = \"task 2\" , args = [ \"* / .txt\" ], kwargs = { \"recursive\" : True }, download = \"testfiles\" , output_to = \"glob_res\" , ) PythonTask ( function = \"builtins.print\" , name = \"task 3\" , args = [ \"<% $.files.testfiles %>\" , \"<% $.outputs.glob_res %>\" ], parents = t1 , ) description = Description . from_dag ( dag , wf_def_name = wf_def_name , wf_def_description = wf_def_description ) Parameters name (dict) Specify a name for the workflow definition description_string (str) Specify a description string in markdown format from_dag ( dag , wf_def_name='' , wf_def_description='' ) Generates a workflow definition description from a pytailor DAG class Parameters dag (DAG) Specify your DAG for workflow definition wf_def_name (str) Specify a name for workflow definition wf_def_description (str) Specify an overall description, what are the main objectives of your workflow definition? What are the main steps in the DAG? to_string ( self ) to_markdown ( self , filename='Readme.MD' )","title":"Description"},{"location":"api/taskdefs/","text":"Task definition classes PythonTask class pytailor. PythonTask ( function , name=None , parents=None , owner=None , download=None , upload=None , args=None , kwargs=None , output_to=None , output_extraction=None , use_storage_dirs=True ) Task for running python code. Basic usage pytask = PythonTask ( function = 'builtins.print' , args = 'Hello, world!' , name = 'My first task' ) Parameters function (str) Python callable. Must be importable in the executing python env. E.g. 'mymodule.myfunc'. name (str, optional) A default name is used if not provided. parents (BaseTask or List[BaseTask], optional) Specify one or more upstream tasks that this task depends on. download (str or list, optional) Provide one or more file tags. These file tags refer to files in the storage object associated with the workflow run. upload (dict, optional) Specify files to send back to the storage object after a task has been run. Dict format is {tag1: val1, tag2: val2, ...} where val can be: one or more query expressions(str og list) which is applied to the return value from callable . File names resulting from the query are then uploaded to storage under the given tag. one or more glob-style strings (str og list) which is applied in the task working dir. matching files are uploaded under the given tag. args (list or str, optional) Arguments to be passed as positional arguments to function . Arguments can be given as ordinary python values or as query expressions. See the examples for how query expressions are used. kwargs (dict or str, optional) Arguments to be passed as keyword arguments to function . Arguments can be given as ordinary python values or as query expressions. See the examples for how query expressions are used. output_to (str, optional) The return value of the callable is stored in a tag with the specified name. This value is made available for later use through the expression $.outputs. . output_extraction (dict, optional) An expression to extract parts of the return value of the callable. The keys of the dictionary are used as tags, and the values becomes available for later use through the expressions $.outputs. , $.outputs. , and so on. to_dict ( self ) Serialize task definition. from_dict ( d ) Create from serialized task definition. DAG class pytailor. DAG ( tasks=None , name=None , parents=None , owner=None , links=None ) Represents a Directed Acyclic Graph, i.e. a DAG. Parameters tasks : BaseTask or List[BaseTask] Python, Duplicate or WorkflowSpec objects. name : str, optional A default name is used if not provided. parents : BaseTask or List[BaseTask], optional Specify one or more upstream tasks that this task depends on. links : dict, optional Parent/children relationships can be specified with the dict on the form {parent_def: [child_def1, child_def2], ...}. Definition references may either be indices (ints) into tasks or BaseTask instances. Note that links may also be defined on task objects with the parents argument instead of using links: (parents=[parent_def1, parent_def2]) to_dict ( self ) from_dict ( d )","title":"Task definition classes"},{"location":"api/taskdefs/#task-definition-classes","text":"","title":"Task definition classes"},{"location":"api/taskdefs/#pythontask","text":"class pytailor. PythonTask ( function , name=None , parents=None , owner=None , download=None , upload=None , args=None , kwargs=None , output_to=None , output_extraction=None , use_storage_dirs=True ) Task for running python code. Basic usage pytask = PythonTask ( function = 'builtins.print' , args = 'Hello, world!' , name = 'My first task' ) Parameters function (str) Python callable. Must be importable in the executing python env. E.g. 'mymodule.myfunc'. name (str, optional) A default name is used if not provided. parents (BaseTask or List[BaseTask], optional) Specify one or more upstream tasks that this task depends on. download (str or list, optional) Provide one or more file tags. These file tags refer to files in the storage object associated with the workflow run. upload (dict, optional) Specify files to send back to the storage object after a task has been run. Dict format is {tag1: val1, tag2: val2, ...} where val can be: one or more query expressions(str og list) which is applied to the return value from callable . File names resulting from the query are then uploaded to storage under the given tag. one or more glob-style strings (str og list) which is applied in the task working dir. matching files are uploaded under the given tag. args (list or str, optional) Arguments to be passed as positional arguments to function . Arguments can be given as ordinary python values or as query expressions. See the examples for how query expressions are used. kwargs (dict or str, optional) Arguments to be passed as keyword arguments to function . Arguments can be given as ordinary python values or as query expressions. See the examples for how query expressions are used. output_to (str, optional) The return value of the callable is stored in a tag with the specified name. This value is made available for later use through the expression $.outputs. . output_extraction (dict, optional) An expression to extract parts of the return value of the callable. The keys of the dictionary are used as tags, and the values becomes available for later use through the expressions $.outputs. , $.outputs. , and so on. to_dict ( self ) Serialize task definition. from_dict ( d ) Create from serialized task definition.","title":"PythonTask"},{"location":"api/taskdefs/#dag","text":"class pytailor. DAG ( tasks=None , name=None , parents=None , owner=None , links=None ) Represents a Directed Acyclic Graph, i.e. a DAG.","title":"DAG"},{"location":"documentation/concepts/","text":"Tailor concepts DAGs DAGs are used to define relationships between tasks in a Workflow in the form of a Directed Acyclic Graph. Task definitions Task definitions are parameterized and reusable blueprints for computing tasks. In Pytailor, tasks definitions are created using the task definition classes The available task definition classes are: PythonTask This is the basic building block. Used to define the execution of a single Python function (callable). BranchTask ... By combining the different task types, arbitrary complex tasks can be defined. A non-trivial task definition will typically consist of a DAG at the top-level, which in turn consist of other task definitions as illustrated in ... Note Tailor is still in development and more task definition classes are likely to be introduced in the future to extend functionality. Workflows Workflows are instantiated DAGs with a given set of inputs and files. Workflows are stored on the Tailor backend under a given Project . dag project inputs (parameters, JSON) files (inputs files) worker requirements In Pytailor, workflows are represented by the Workflow class Tasks Tasks are instantiated task definitions . Belongs to a Workflow . Workflow definitions Workflow definitions are used to store a DAG along with requirements (schema) for inputs and files. Workflow definitions are stored in the backend and can be made available for other users. Workflow subscriptions Workflow definitions can be shared between users with Workflow subscriptions . Tailor Accounts Tailor Projects","title":"Concepts"},{"location":"documentation/concepts/#tailor-concepts","text":"","title":"Tailor concepts"},{"location":"documentation/concepts/#dags","text":"DAGs are used to define relationships between tasks in a Workflow in the form of a Directed Acyclic Graph.","title":"DAGs"},{"location":"documentation/concepts/#task-definitions","text":"Task definitions are parameterized and reusable blueprints for computing tasks. In Pytailor, tasks definitions are created using the task definition classes The available task definition classes are: PythonTask This is the basic building block. Used to define the execution of a single Python function (callable). BranchTask ... By combining the different task types, arbitrary complex tasks can be defined. A non-trivial task definition will typically consist of a DAG at the top-level, which in turn consist of other task definitions as illustrated in ... Note Tailor is still in development and more task definition classes are likely to be introduced in the future to extend functionality.","title":"Task definitions"},{"location":"documentation/concepts/#workflows","text":"Workflows are instantiated DAGs with a given set of inputs and files. Workflows are stored on the Tailor backend under a given Project . dag project inputs (parameters, JSON) files (inputs files) worker requirements In Pytailor, workflows are represented by the Workflow class","title":"Workflows"},{"location":"documentation/concepts/#tasks","text":"Tasks are instantiated task definitions . Belongs to a Workflow .","title":"Tasks"},{"location":"documentation/concepts/#workflow-definitions","text":"Workflow definitions are used to store a DAG along with requirements (schema) for inputs and files. Workflow definitions are stored in the backend and can be made available for other users.","title":"Workflow definitions"},{"location":"documentation/concepts/#workflow-subscriptions","text":"Workflow definitions can be shared between users with Workflow subscriptions .","title":"Workflow subscriptions"},{"location":"documentation/concepts/#tailor-accounts","text":"","title":"Tailor Accounts"},{"location":"documentation/concepts/#tailor-projects","text":"","title":"Tailor Projects"},{"location":"documentation/contexts/","text":"Contexts Contexts represents the data and files associated with a workflow. The context consist of three datastructures: inputs outputs files inputs are provided by the user during workflow specification, e.g. from tailor import PythonTask , WorkflowSpec # a task definition t1 = Pythontask ( function = 'builtins.abs' , args = '<% $.inputs.input_number %>' ) t2 = Pythontask ( function = 'builtins.abs' , args = '<% $.inputs.input_number %>' ) inputs = { input_number : - 123 } wf_spec = WorkflowSpec ( ) Note The inputs and outputs datastructures must be JSON-serializable, which limits the data types which can be used. In the future more sophisticated serialization may be applied to allow other object types, e.g. numpy arrays. For data that is not JSON-compatible you can serialize the data to file and use the file-piping mechanisms to send the data to your tasks. Context queries Contexts can be queried using the YAQL query language. Context queries can be used in task definitions as a means to parameterize inputs. When jobs are executed, the queries are performed on the context associated with the current workflow run. Context queries, when used in task definitions, are specified using a special syntax: '<% query-expression %>' . This syntax tells tailor to Scoped contexts Scoped contexts arise when tasks are duplicated. Consider the following DAG, consisting of two PythonTasks: +---+ | t1 | PythonTask ( ... , output_to = 'out' ) +-+-+ | | +- v -+ | t2 | PythonTask ( ... , args = '<% $.outputs.out %>' ) +---+ When this DAG is duplicated with a BranchTask","title":"Contexts"},{"location":"documentation/contexts/#contexts","text":"Contexts represents the data and files associated with a workflow. The context consist of three datastructures: inputs outputs files inputs are provided by the user during workflow specification, e.g. from tailor import PythonTask , WorkflowSpec # a task definition t1 = Pythontask ( function = 'builtins.abs' , args = '<% $.inputs.input_number %>' ) t2 = Pythontask ( function = 'builtins.abs' , args = '<% $.inputs.input_number %>' ) inputs = { input_number : - 123 } wf_spec = WorkflowSpec ( ) Note The inputs and outputs datastructures must be JSON-serializable, which limits the data types which can be used. In the future more sophisticated serialization may be applied to allow other object types, e.g. numpy arrays. For data that is not JSON-compatible you can serialize the data to file and use the file-piping mechanisms to send the data to your tasks.","title":"Contexts"},{"location":"documentation/contexts/#context-queries","text":"Contexts can be queried using the YAQL query language. Context queries can be used in task definitions as a means to parameterize inputs. When jobs are executed, the queries are performed on the context associated with the current workflow run. Context queries, when used in task definitions, are specified using a special syntax: '<% query-expression %>' . This syntax tells tailor to","title":"Context queries"},{"location":"documentation/contexts/#scoped-contexts","text":"Scoped contexts arise when tasks are duplicated. Consider the following DAG, consisting of two PythonTasks: +---+ | t1 | PythonTask ( ... , output_to = 'out' ) +-+-+ | | +- v -+ | t2 | PythonTask ( ... , args = '<% $.outputs.out %>' ) +---+ When this DAG is duplicated with a BranchTask","title":"Scoped contexts"},{"location":"documentation/getting_started/","text":"Getting started To use Pytailor you need to connect to a Tailor backend. The easiest way to get started with Tailor is to sign up for a free account at Tailor.wf . For other options please contact us . In the following it us assumed that you are using Tailor.wf as your backend service. Installation First time setup 1. Install pytailor Official releases of pytailor are available on pypi and can easily be installed with pip: pip install pytailor Note You can also clone the repository on github and install pytailor with poetry : git clone https://github.com/entailor/pytailor.git Then, from the project root run: poetry install To install without development dependencies: poetry install --no-dev 2. Configure backend When pytailor is installed your ca use the CLI to set up a barebone config file: tailor init This command generates a config file .tailor/config.toml under your home directory with the following content: API_KEY = < API KEY GOES HERE > API_BASE_URL = < URL FOR THE BACKEND REST API GOES HERE > Note It is also possible to configure pytailor with environmental variables by prefixing the environmental variables with PYTAILOR_ . E.g. to set the API, key put it in an environmental variable called PYTAILOR_API_KEY . Update Pytailor Basic usage With Pytailor installed and a backend properly configured you should be able to run the following example: from tailor import PythonTask , DAG In this example, several key concepts are illustrated: ... walk through code... Please consult the Consepts page...","title":"Getting started"},{"location":"documentation/getting_started/#getting-started","text":"To use Pytailor you need to connect to a Tailor backend. The easiest way to get started with Tailor is to sign up for a free account at Tailor.wf . For other options please contact us . In the following it us assumed that you are using Tailor.wf as your backend service.","title":"Getting started"},{"location":"documentation/getting_started/#installation","text":"","title":"Installation"},{"location":"documentation/getting_started/#first-time-setup","text":"","title":"First time setup"},{"location":"documentation/getting_started/#1-install-pytailor","text":"Official releases of pytailor are available on pypi and can easily be installed with pip: pip install pytailor Note You can also clone the repository on github and install pytailor with poetry : git clone https://github.com/entailor/pytailor.git Then, from the project root run: poetry install To install without development dependencies: poetry install --no-dev","title":"1. Install pytailor"},{"location":"documentation/getting_started/#2-configure-backend","text":"When pytailor is installed your ca use the CLI to set up a barebone config file: tailor init This command generates a config file .tailor/config.toml under your home directory with the following content: API_KEY = < API KEY GOES HERE > API_BASE_URL = < URL FOR THE BACKEND REST API GOES HERE > Note It is also possible to configure pytailor with environmental variables by prefixing the environmental variables with PYTAILOR_ . E.g. to set the API, key put it in an environmental variable called PYTAILOR_API_KEY .","title":"2. Configure backend"},{"location":"documentation/getting_started/#update-pytailor","text":"","title":"Update Pytailor"},{"location":"documentation/getting_started/#basic-usage","text":"With Pytailor installed and a backend properly configured you should be able to run the following example: from tailor import PythonTask , DAG In this example, several key concepts are illustrated: ... walk through code... Please consult the Consepts page...","title":"Basic usage"}]}